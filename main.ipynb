{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import varie e inizializzazione delle variabili dei modelli e del tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from IRESNs_tensorflow.time_series_datasets import *\n",
    "from IRESNs_tensorflow.models import ESN, IRESN, IIRESN, IIRESNvsr\n",
    "from tensorflow import keras\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
    "DATASET_NAME = \"CharacterTrajectories\"\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "\n",
    "READOUT_ACTIVATION_BINARY = keras.activations.sigmoid\n",
    "LOSS_FUNCTION_BINARY = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "READOUT_ACTIVATION = keras.activations.softmax\n",
    "LOSS_FUNCTION = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Dataset dependent settings\n",
    "RESERVOIRS = 3\n",
    "OUTPUT_UNITS = 20\n",
    "\n",
    "# Tuner settings\n",
    "MAX_EPOCHS = 3\n",
    "PATIENCE = 1\n",
    "MAX_TRIALS = 5\n",
    "OVERWRITE = False\n",
    "TRIALS = 1\n",
    "\n",
    "BENCHMARKS_TRIALS = 1\n",
    "\n",
    "MINVAL = 0.01\n",
    "MAXVAL = 1.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definizione della funzione utilizzata dal tuner per istanziare i modelli per la model selection.\n",
    "Si definisce un modello ESN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def build_ESN(tuner):\n",
    "    ESN_model = ESN(units=100,\n",
    "                    connectivity=tuner.Float('connectivity', min_value=0.01, max_value=1.),\n",
    "                    spectral_radius=tuner.Float('spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    bias_scaling=tuner.Float('bias scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                    output_units=OUTPUT_UNITS,\n",
    "                    readout_activation=READOUT_ACTIVATION,\n",
    "                    )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    ESN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return ESN_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def build_IRESN(tuner):\n",
    "    connectivity = [tuner.Float('connectivity ' + str(i), min_value=0.01, max_value=1.) for i in range(RESERVOIRS)]\n",
    "    sr = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in range(RESERVOIRS)]\n",
    "\n",
    "    IRESN_model = IRESN(units=100,\n",
    "                        sub_reservoirs=RESERVOIRS,\n",
    "                        connectivity=connectivity,\n",
    "                        spectral_radius=sr,\n",
    "                        input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                        output_units=OUTPUT_UNITS,\n",
    "                        readout_activation=READOUT_ACTIVATION,\n",
    "                        )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IRESN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IRESN_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def build_IIRESN(tuner):\n",
    "    sr = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in range(RESERVOIRS)]\n",
    "\n",
    "    \"\"\"\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     tuner.Float('connectivity ' + str(i) + '->' + str(j), min_value=0., max_value=1.)\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    off_diagonal_limits = [[0. if i == j else\n",
    "                     tuner.Float('limit ' + str(i) + '->' + str(j), min_value=0., max_value=1.)\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "    \"\"\"\n",
    "    limit = tuner.Float('limit X->Y', min_value=0., max_value=1.)\n",
    "    off_diagonal_limits = [[0. if i == j else limit  # 0 sulla diagonale limit su tutte le posizioni off-diagonali\n",
    "                            for i in range(RESERVOIRS)]\n",
    "                           for j in range(RESERVOIRS)]\n",
    "\n",
    "    fixed = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     fixed\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    IIRENS_model = IIRESN(units=100,\n",
    "                          sub_reservoirs=RESERVOIRS,\n",
    "                          connectivity=connectivity,\n",
    "                          spectral_radius=sr,\n",
    "                          off_diagonal_limits=off_diagonal_limits,\n",
    "                          input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                          output_units=OUTPUT_UNITS,\n",
    "                          readout_activation=READOUT_ACTIVATION,\n",
    "                          )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRENS_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRENS_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def build_IIRESNvsr(tuner):\n",
    "    sr = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in range(RESERVOIRS)]\n",
    "\n",
    "    \"\"\"\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     tuner.Float('connectivity ' + str(i) + '->' + str(j), min_value=0., max_value=1.)\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    off_diagonal_limits = [[0. if i == j else\n",
    "                     tuner.Float('limit ' + str(i) + '->' + str(j), min_value=0., max_value=1.)\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "    \"\"\"\n",
    "\n",
    "    fixed = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     fixed\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    limit = tuner.Float('limit X->Y', min_value=0., max_value=1.)\n",
    "    off_diagonal_limits = [[0. if i == j else limit  # 0 sulla diagonale limit su tutte le posizioni off-diagonali\n",
    "                            for i in range(RESERVOIRS)]\n",
    "                           for j in range(RESERVOIRS)]\n",
    "\n",
    "    partitions = [tuner.Float('partition ' + str(i), min_value=0.1, max_value=1.0) for i in range(RESERVOIRS)]\n",
    "    total = sum(partitions)\n",
    "    # Normalize the partition vector now sum(partitions) == 1.\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))\n",
    "\n",
    "    IIRESNvsr_model = IIRESNvsr(units=100,\n",
    "                                partitions=partitions,\n",
    "                                sub_reservoirs=RESERVOIRS,\n",
    "                                connectivity=connectivity,\n",
    "                                off_diagonal_limits=off_diagonal_limits,\n",
    "                                spectral_radius=sr,\n",
    "                                input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                                bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                                leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                                output_units=OUTPUT_UNITS,\n",
    "                                readout_activation=READOUT_ACTIVATION,\n",
    "                                )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRESNvsr_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRESNvsr_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(DATASET_DIR, DATASET_NAME, DATASET_NAME + '_TRAIN.ts')\n",
    "test_path = os.path.join(DATASET_DIR, DATASET_NAME, DATASET_NAME + '_TEST.ts')\n",
    "\n",
    "x_train_all, y_train_all = load_sktime_dataset(train_path)\n",
    "x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "train_set = (x_train, y_train)\n",
    "val_set = (x_val, y_val)\n",
    "test_set = (x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project models/CharacterTrajectories/IIRESNvsr/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from models/CharacterTrajectories/IIRESNvsr/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/3\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.7557 - accuracy: 0.1691 - val_loss: 2.4147 - val_accuracy: 0.3298\n",
      "Epoch 2/3\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 2.2296 - accuracy: 0.5074 - val_loss: 2.0212 - val_accuracy: 0.5787\n",
      "Epoch 3/3\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.9004 - accuracy: 0.5830 - val_loss: 1.7551 - val_accuracy: 0.6638\n",
      "45/45 [==============================] - 0s 406us/step - loss: 1.7622 - accuracy: 0.6469\n",
      "     Train accuracy: 0.5829831957817078\n",
      "Validation accuracy: 0.6638298034667969\n",
      "      Test accuracy: 0.6469359397888184\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "working_dir = os.path.join(\"models\", DATASET_NAME)\n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_IIRESNvsr,  # build_ESN build_IRESN, build_IIRESN, build_IIRESNvsr\n",
    "    objective='val_accuracy',\n",
    "    max_trials=MAX_TRIALS,\n",
    "    seed=42,\n",
    "    directory=working_dir,\n",
    "    project_name='IIRESNvsr',  # change this for every model\n",
    "    overwrite=OVERWRITE,\n",
    "    executions_per_trial=TRIALS,\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "             callbacks=[\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "             ])\n",
    "\n",
    "best_model_hp = tuner.get_best_hyperparameters()[0]\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "for i in range(BENCHMARKS_TRIALS):\n",
    "    test_model = tuner.hypermodel.build(best_model_hp)\n",
    "    history = test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE,\n",
    "                                                                      restore_best_weights=True)])\n",
    "    test_loss, accuracy = test_model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(\"     Train accuracy:\", history.history['accuracy'][-1])\n",
    "    print(\"Validation accuracy:\", history.history['val_accuracy'][-1])\n",
    "    print(\"      Test accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build some custom Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experimental model with kernel equals to IRESN and recurrent kernel equals to ESN.\n",
    "\"\"\"\n",
    "\n",
    "from IRESNs_tensorflow.models import ESNInterface\n",
    "from IRESNs_tensorflow import layer\n",
    "from IRESNs_tensorflow import initializers\n",
    "\n",
    "\n",
    "class CustomESN(ESNInterface):\n",
    "    def __init__(self,\n",
    "                 units: int,\n",
    "                 sub_reservoirs: int,\n",
    "                 output_units: int,\n",
    "                 reservoir_activation=tf.keras.activations.tanh,\n",
    "                 readout_activation=tf.nn.tanh,\n",
    "                 spectral_radius: float = 0.9,\n",
    "                 connectivity: float = 1.,\n",
    "                 input_scaling: float = 1.,\n",
    "                 bias_scaling=None,\n",
    "                 leaky=0.1,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        kernel_init = initializers.SplitKernel(sub_reservoirs, input_scaling)\n",
    "\n",
    "        if connectivity == 1.0:\n",
    "            recurrent_kernel_init = initializers.FullConnected(spectral_radius)\n",
    "        else:\n",
    "            recurrent_kernel_init = initializers.RecurrentKernel(connectivity, spectral_radius)\n",
    "\n",
    "        self.use_bias = bias_scaling is not None\n",
    "        if self.use_bias:\n",
    "            bias_init = tf.keras.initializers.RandomUniform(minval=-bias_scaling, maxval=bias_scaling)\n",
    "        else:\n",
    "            bias_init = None\n",
    "\n",
    "        self.reservoir = keras.Sequential([\n",
    "            keras.layers.Masking(),\n",
    "            layer.ESN(units, leaky,\n",
    "                      activation=reservoir_activation,\n",
    "                      use_bias=self.use_bias,\n",
    "                      kernel_initializer=kernel_init,\n",
    "                      recurrent_initializer=recurrent_kernel_init,\n",
    "                      bias_initializer=bias_init,\n",
    "                      ),\n",
    "        ])\n",
    "        self.readout = keras.Sequential([\n",
    "            keras.layers.Dense(output_units, activation=readout_activation, name=\"readout\")\n",
    "        ])\n",
    "\n",
    "\n",
    "def build_CustomESN(tuner):\n",
    "    custom_model = CustomESN(units=100,\n",
    "                          sub_reservoirs=RESERVOIRS,\n",
    "                          connectivity=tuner.Float('connectivity', min_value=0.01, max_value=1.),\n",
    "                          spectral_radius=tuner.Float('spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          bias_scaling=tuner.Float('bias scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                          output_units=OUTPUT_UNITS,\n",
    "                          readout_activation=READOUT_ACTIVATION\n",
    "                          )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    custom_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return custom_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project models/CharacterTrajectories/CustomESN/oracle.json\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |274               |?                 \n",
      "connectivity      |0.048166          |?                 \n",
      "spectral radius   |0.61872           |?                 \n",
      "input scaling     |0.41509           |?                 \n",
      "bias scaling      |1.3335            |?                 \n",
      "leaky             |0.35833           |?                 \n",
      "learning rate     |0.0015582         |?                 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential\" (type Sequential).\n\nIn this `tf.Variable` creation, the initial value's shape ((3, 100)) is not compatible with the explicitly supplied `shape` argument ((100, 100)).\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(952, 180, 3), dtype=float64)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [70]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m tuner \u001B[38;5;241m=\u001B[39m RandomSearch(\n\u001B[1;32m      2\u001B[0m     build_CustomESN,  \u001B[38;5;66;03m# build_ESN build_IRESN, build_IIRESN, build_IIRESNvsr\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     objective\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m     executions_per_trial\u001B[38;5;241m=\u001B[39mTRIALS,\n\u001B[1;32m     10\u001B[0m )\n\u001B[0;32m---> 12\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMAX_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m             \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPATIENCE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m             \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m--> 179\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m results \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:304\u001B[0m, in \u001B[0;36mTuner.run_trial\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(model_checkpoint)\n\u001B[1;32m    303\u001B[0m copied_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[0;32m--> 304\u001B[0m obj_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_and_fit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcopied_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;66;03m# objective left unspecified,\u001B[39;00m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# and objective value is not a single float.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj_value, (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m))\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault_objective\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    311\u001B[0m ):\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:234\u001B[0m, in \u001B[0;36mTuner._build_and_fit_model\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    232\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[1;32m    233\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[0;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[0;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/IRESNs-tensorflow/IRESNs_tensorflow/models.py:30\u001B[0m, in \u001B[0;36mESNInterface.fit\u001B[0;34m(self, x, y, *args, **kwargs)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;66;03m# applies the reservoirs to all the input sequences in the training set\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m     x_train_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreservoir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# does the same for the validation set\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     x_val, y_val \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_data\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/IRESNs-tensorflow/IRESNs_tensorflow/layer.py:104\u001B[0m, in \u001B[0;36mReservoir.build\u001B[0;34m(self, inputs_shape)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not infer input size from inputs.get_shape()[-1]. Shape received is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    101\u001B[0m         \u001B[38;5;241m%\u001B[39m inputs_shape\n\u001B[1;32m    102\u001B[0m     )\n\u001B[0;32m--> 104\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_weight\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkernel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munits\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurrent_kernel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_weight(\n\u001B[1;32m    113\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecurrent_kernel\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    114\u001B[0m     shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munits, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munits],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    117\u001B[0m     dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    118\u001B[0m )\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_bias:\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nIn this `tf.Variable` creation, the initial value's shape ((3, 100)) is not compatible with the explicitly supplied `shape` argument ((100, 100)).\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(952, 180, 3), dtype=float64)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_CustomESN,  # build_ESN build_IRESN, build_IIRESN, build_IIRESNvsr\n",
    "    objective='val_accuracy',\n",
    "    max_trials=MAX_TRIALS,\n",
    "    seed=42,\n",
    "    directory=working_dir,\n",
    "    project_name='CustomESN',  # change this for every model\n",
    "    overwrite=OVERWRITE,\n",
    "    executions_per_trial=TRIALS,\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "             callbacks=[\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "             ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}