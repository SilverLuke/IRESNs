{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import varie e inizializzazione delle variabili dei modelli e del tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:42: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:45: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:46: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IRESNs_tensorflow.time_series_datasets import *\n",
    "from IRESNs_tensorflow.models import ESN, IRESN, IIRESN\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
    "DATASET_NAME = \"CharacterTrajectories\"\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "\n",
    "READOUT_ACTIVATION_BINARY = keras.activations.sigmoid\n",
    "LOSS_FUNCTION_BINARY = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "READOUT_ACTIVATION = keras.activations.softmax\n",
    "LOSS_FUNCTION = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Dataset dependent settings\n",
    "RESERVOIRS = 3\n",
    "OUTPUT_UNITS = 20\n",
    "\n",
    "# Tuner settings\n",
    "MAX_EPOCHS = 3\n",
    "PATIENCE = 1\n",
    "MAX_TRIALS = 5\n",
    "OVERWRITE = True\n",
    "TRIALS = 1\n",
    "\n",
    "BENCHMARKS_TRIALS = 1\n",
    "\n",
    "MINVAL = 0.01\n",
    "MAXVAL = 1.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definizione della funzione utilizzata dal tuner per istanziare i modelli per la model selection.\n",
    "Nella seguente cella si definisce un modello di tipo ESN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def build_ESN(tuner):\n",
    "    ESN_model = ESN(units=100,\n",
    "                    connectivity=tuner.Float('connectivity', min_value=0.01, max_value=1.),\n",
    "                    spectral_radius=tuner.Float('spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    bias_scaling=tuner.Float('bias scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                    leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                    output_units=OUTPUT_UNITS,\n",
    "                    readout_activation=READOUT_ACTIVATION,\n",
    "                    )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    ESN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return ESN_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In seguito vengono definiti due tipi di modelli\n",
    "- IRESN ha #'RESERVOIRS' al suo interno di tipo ESN tutti della stessa dimensione non comunicanti.\n",
    "- IIRESN #'RESERVOIRS' al suo interno di tipo ESN tutti della stessa dimensione comunicanti."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def build_IRESN(tuner):\n",
    "    connectivity = [tuner.Float('connectivity ' + str(i), min_value=0.01, max_value=1.) for i in range(RESERVOIRS)]\n",
    "    normalization = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in\n",
    "                     range(RESERVOIRS)]\n",
    "\n",
    "    IRESN_model = IRESN(sub_reservoirs=RESERVOIRS,\n",
    "                        output_units=OUTPUT_UNITS,\n",
    "                        units=100,\n",
    "                        connectivity=connectivity,\n",
    "                        normalization=normalization,\n",
    "                        input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                        readout_activation=READOUT_ACTIVATION,\n",
    "                        )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IRESN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IRESN_model\n",
    "\n",
    "\n",
    "def build_IIRESN(tuner):\n",
    "    norm = tuner.Float('norm', min_value=MINVAL, max_value=MAXVAL)\n",
    "    normalization = [[tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) if i == j else\n",
    "                      norm\n",
    "                      for i in range(RESERVOIRS)]\n",
    "                     for j in range(RESERVOIRS)]\n",
    "\n",
    "    ic_density = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     ic_density\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    IIRENS_model = IIRESN(units=100,\n",
    "                          sub_reservoirs=RESERVOIRS,\n",
    "                          connectivity=connectivity,\n",
    "                          normalization=normalization,\n",
    "                          input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                          output_units=OUTPUT_UNITS,\n",
    "                          readout_activation=READOUT_ACTIVATION,\n",
    "                          )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRENS_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRENS_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In seguito vengono definiti due varianti ai modelli definiti precedentemente\n",
    "- IRESNvsr sub-reseroir di dimensione variabile, definita tramite il parametro di funzione 'vsr'.\n",
    "- IIRESNvsr sub-reseroir di dimensione variabile, definita tramite il parametro di funzione 'vsr'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Generate and Normalize the partition vector. sum(partitions) == 1.\n",
    "def generate_partitions(tuner):\n",
    "    partitions = [tuner.Float('partition ' + str(i), min_value=0.1, max_value=1.0) for i in range(RESERVOIRS)]\n",
    "    total = sum(partitions)\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def build_IRESNvsr(tuner):\n",
    "    sr = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in range(RESERVOIRS)]\n",
    "    connectivity = [tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) for i in range(RESERVOIRS)]\n",
    "\n",
    "    IRESNvsr_model = IRESN(units=100,\n",
    "                           sub_reservoirs=RESERVOIRS,\n",
    "                           output_units=OUTPUT_UNITS,\n",
    "                           connectivity=connectivity,\n",
    "                           normalization=sr,\n",
    "                           vsr=generate_partitions(tuner),\n",
    "                           input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                           bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                           leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                           readout_activation=READOUT_ACTIVATION,\n",
    "                           )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IRESNvsr_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IRESNvsr_model\n",
    "\n",
    "\n",
    "def build_IIRESNvsr(tuner):\n",
    "    ic_norm = tuner.Float('norm 2', min_value=MINVAL, max_value=MAXVAL)\n",
    "    normalization = [[tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) if i == j else\n",
    "                      ic_norm\n",
    "                      for i in range(RESERVOIRS)]\n",
    "                     for j in range(RESERVOIRS)]\n",
    "\n",
    "    ic_density = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     ic_density\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    IIRESNvsr_model = IIRESN(units=100,\n",
    "                             sub_reservoirs=RESERVOIRS,\n",
    "                             connectivity=connectivity,\n",
    "                             normalization=normalization,\n",
    "                             vsr=generate_partitions(tuner),\n",
    "                             input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                             output_units=OUTPUT_UNITS,\n",
    "                             readout_activation=READOUT_ACTIVATION,\n",
    "                             )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRESNvsr_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRESNvsr_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In questi modelli viene tolto il parametro vsr e i valori di normalizzazione dei sub-reservoir ma aggiunto il global spectral radius."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_IRESNgsr(tuner):\n",
    "    connectivity = [tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) for i in range(RESERVOIRS)]\n",
    "\n",
    "    IRESNvsr_model = IRESN(units=100,\n",
    "                           sub_reservoirs=RESERVOIRS,\n",
    "                           output_units=OUTPUT_UNITS,\n",
    "                           connectivity=connectivity,\n",
    "                           gsr=tuner.Float('global spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                           input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                           bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                           leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                           readout_activation=READOUT_ACTIVATION,\n",
    "                           )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IRESNvsr_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IRESNvsr_model\n",
    "\n",
    "\n",
    "def build_IIRESNgsr(tuner):\n",
    "    ic_density = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     ic_density\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    IIRESNvsr_model = IIRESN(units=100,\n",
    "                             sub_reservoirs=RESERVOIRS,\n",
    "                             connectivity=connectivity,\n",
    "                             gsr=tuner.Float('global spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                             output_units=OUTPUT_UNITS,\n",
    "                             readout_activation=READOUT_ACTIVATION,\n",
    "                             )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRESNvsr_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRESNvsr_model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelli definiti come nella cella precedente ma viene reintrodotta la normalizzazione dei sub-reservoir e rimane il global spectral radius."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def build_IRESN_norm_gsr(tuner):\n",
    "    connectivity = [tuner.Float('connectivity ' + str(i), min_value=0.01, max_value=1.) for i in range(RESERVOIRS)]\n",
    "    sr = [tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) for i in range(RESERVOIRS)]\n",
    "\n",
    "    IRESN_model = IRESN(units=100,\n",
    "                        sub_reservoirs=RESERVOIRS,\n",
    "                        connectivity=connectivity,\n",
    "                        normalization=sr,\n",
    "                        gsr=tuner.Float('global spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                        leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                        output_units=OUTPUT_UNITS,\n",
    "                        readout_activation=READOUT_ACTIVATION,\n",
    "                        )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IRESN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IRESN_model\n",
    "\n",
    "\n",
    "def build_IIRESN_norm_gsr(tuner):\n",
    "    norm = tuner.Float('norm', min_value=MINVAL, max_value=MAXVAL)\n",
    "    normalization = [[tuner.Float('spectral radius ' + str(i), min_value=MINVAL, max_value=MAXVAL) if i == j else norm\n",
    "                      # 0 sulla diagonale limit su tutte le posizioni off-diagonali\n",
    "                      for i in range(RESERVOIRS)]\n",
    "                     for j in range(RESERVOIRS)]\n",
    "\n",
    "    ic_density = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "    connectivity = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                     ic_density\n",
    "                     for i in range(RESERVOIRS)]\n",
    "                    for j in range(RESERVOIRS)]\n",
    "\n",
    "    IIRENS_model = IIRESN(units=100,\n",
    "                          sub_reservoirs=RESERVOIRS,\n",
    "                          connectivity=connectivity,\n",
    "                          normalization=normalization,\n",
    "                          gsr=tuner.Float('global spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          bias_scaling=tuner.Float('bias_scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                          leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                          output_units=OUTPUT_UNITS,\n",
    "                          readout_activation=READOUT_ACTIVATION,\n",
    "                          )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    IIRENS_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return IIRENS_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(DATASET_DIR, DATASET_NAME, DATASET_NAME + '_TRAIN.ts')\n",
    "test_path = os.path.join(DATASET_DIR, DATASET_NAME, DATASET_NAME + '_TEST.ts')\n",
    "\n",
    "x_train_all, y_train_all = load_sktime_dataset(train_path)\n",
    "x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "train_set = (x_train, y_train)\n",
    "val_set = (x_val, y_val)\n",
    "test_set = (x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 00s]\n",
      "val_accuracy: 0.2574467957019806\n",
      "\n",
      "Best val_accuracy So Far: 0.3510638177394867\n",
      "Total elapsed time: 00h 00m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/3\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5638 - accuracy: 0.1828 - val_loss: 2.3376 - val_accuracy: 0.2511\n",
      "Epoch 2/3\n",
      "30/30 [==============================] - 0s 896us/step - loss: 2.1780 - accuracy: 0.2973 - val_loss: 2.0697 - val_accuracy: 0.3468\n",
      "Epoch 3/3\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 2.0479 - accuracy: 0.3183 - val_loss: 1.9700 - val_accuracy: 0.3617\n",
      "45/45 [==============================] - 0s 345us/step - loss: 1.9488 - accuracy: 0.3753\n",
      "     Train accuracy: 0.3182772994041443\n",
      "Validation accuracy: 0.3617021143436432\n",
      "      Test accuracy: 0.37534818053245544\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "working_dir = os.path.join(\"models\", DATASET_NAME)\n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_IIRESN,\n",
    "    # build_ESN\n",
    "    # build_IRESN, build_IRESNvsr, build_IRESNgsr, build_IRESN_norm_gsr,\n",
    "    # build_IIRESN, build_IIRESNvsr, build_IIRESNvsr, build_IIRESN_norm_gsr\n",
    "    objective='val_accuracy',\n",
    "    max_trials=MAX_TRIALS,\n",
    "    seed=42,\n",
    "    directory=working_dir,\n",
    "    project_name='build_IIRESN',  # change this based on the build function used\n",
    "    overwrite=OVERWRITE,\n",
    "    executions_per_trial=TRIALS,\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "             callbacks=[\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "             ])\n",
    "\n",
    "best_model_hp = tuner.get_best_hyperparameters()[0]\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "for i in range(BENCHMARKS_TRIALS):\n",
    "    test_model = tuner.hypermodel.build(best_model_hp)\n",
    "    history = test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE,\n",
    "                                                                      restore_best_weights=True)])\n",
    "    test_loss, accuracy = test_model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(\"     Train accuracy:\", history.history['accuracy'][-1])\n",
    "    print(\"Validation accuracy:\", history.history['val_accuracy'][-1])\n",
    "    print(\"      Test accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build some custom Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Experimental model with kernel equals to IRESN and recurrent kernel equals to ESN.\n",
    "\"\"\"\n",
    "\n",
    "from IRESNs_tensorflow.models import ESNInterface\n",
    "from IRESNs_tensorflow import layer\n",
    "from IRESNs_tensorflow import initializers\n",
    "\n",
    "\n",
    "class CustomESN(ESNInterface):\n",
    "    def __init__(self,\n",
    "                 units: int,\n",
    "                 sub_reservoirs: int,\n",
    "                 output_units: int,\n",
    "                 reservoir_activation=tf.keras.activations.tanh,\n",
    "                 readout_activation=tf.nn.tanh,\n",
    "                 spectral_radius: float = 0.9,\n",
    "                 connectivity: float = 1.,\n",
    "                 input_scaling: float = 1.,\n",
    "                 bias_scaling=None,\n",
    "                 leaky=0.1,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        kernel_init = initializers.SplitKernel(sub_reservoirs, input_scaling)\n",
    "\n",
    "        if connectivity == 1.0:\n",
    "            recurrent_kernel_init = initializers.FullConnected(spectral_radius)\n",
    "        else:\n",
    "            recurrent_kernel_init = initializers.RecurrentKernel(connectivity, spectral_radius)\n",
    "\n",
    "        self.use_bias = bias_scaling is not None\n",
    "        if self.use_bias:\n",
    "            bias_init = tf.keras.initializers.RandomUniform(minval=-bias_scaling, maxval=bias_scaling)\n",
    "        else:\n",
    "            bias_init = None\n",
    "\n",
    "        self.reservoir = keras.Sequential([\n",
    "            keras.layers.Masking(),\n",
    "            layer.ESN(units, leaky,\n",
    "                      activation=reservoir_activation,\n",
    "                      use_bias=self.use_bias,\n",
    "                      kernel_initializer=kernel_init,\n",
    "                      recurrent_initializer=recurrent_kernel_init,\n",
    "                      bias_initializer=bias_init\n",
    "                      ),\n",
    "        ])\n",
    "        self.readout = keras.Sequential([\n",
    "            keras.layers.Dense(output_units, activation=readout_activation, name=\"readout\")\n",
    "        ])\n",
    "\n",
    "\n",
    "def build_CustomESN(tuner):\n",
    "    custom_model = CustomESN(units=100,\n",
    "                             sub_reservoirs=RESERVOIRS,\n",
    "                             connectivity=tuner.Float('connectivity', min_value=0.01, max_value=1.),\n",
    "                             spectral_radius=tuner.Float('spectral radius', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             input_scaling=tuner.Float('input scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             bias_scaling=tuner.Float('bias scaling', min_value=MINVAL, max_value=MAXVAL),\n",
    "                             leaky=tuner.Float('leaky', min_value=0.01, max_value=1.0),\n",
    "                             output_units=OUTPUT_UNITS,\n",
    "                             readout_activation=READOUT_ACTIVATION\n",
    "                             )\n",
    "\n",
    "    alpha = tuner.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    custom_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return custom_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 00s]\n",
      "val_accuracy: 0.06382978707551956\n",
      "\n",
      "Best val_accuracy So Far: 0.2638297975063324\n",
      "Total elapsed time: 00h 00m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_CustomESN,  # build_ESN build_IRESN, build_IIRESN, build_IIRESNvsr\n",
    "    objective='val_accuracy',\n",
    "    max_trials=MAX_TRIALS,\n",
    "    seed=42,\n",
    "    directory=working_dir,\n",
    "    project_name='CustomESN',  # change this for every model\n",
    "    overwrite=OVERWRITE,\n",
    "    executions_per_trial=TRIALS,\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "             callbacks=[\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "             ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}